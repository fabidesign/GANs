{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-Training",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabidesign/GANs/blob/master/GAN_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gst3rORyI4Vh",
        "colab_type": "text"
      },
      "source": [
        "Heyoo.\n",
        "\n",
        "This notebook is made to create and train generative adverserial networks with stylegan.\n",
        "\n",
        "Click the connect button in the top right to start. Make sure your runtime type is set to GPU!\n",
        "\n",
        "To Use this notebook you basically just have to run every line after the other.\n",
        "\n",
        "I always comment the line below.\n",
        "\n",
        "On the left you can click on the folder icon to see the file structure and download certain files. Very handy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxvU93lzJMcS",
        "colab_type": "text"
      },
      "source": [
        "Install stylegan :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXdb0EKwDGTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BjwawpiJOXf",
        "colab_type": "text"
      },
      "source": [
        "Move to stylegan folder :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh8mHKWKMkqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd stylegan/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHQzVZFjJUYS",
        "colab_type": "text"
      },
      "source": [
        "List the content in that folder, just to check if working :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Hw6PagDGgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/stylegan/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5O3i3iLJai4",
        "colab_type": "text"
      },
      "source": [
        "Make a new folder to load the original pictures :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-D5X1XpwFKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir originals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPyC7ZuPJipZ",
        "colab_type": "text"
      },
      "source": [
        "Move to that folder :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZsD3J6OwFYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/stylegan/originals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P3JPBVnJna9",
        "colab_type": "text"
      },
      "source": [
        "Download a ZIP with all the pictures you want to train on. Must be JPGs and all be of the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ2r31fZwFlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1CubGn9H4ywgIUebecz_qnfds9JghMlim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt-b8SaRJvEO",
        "colab_type": "text"
      },
      "source": [
        "Unzip said folder(You may need to change the name (MMM.zip)) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sios3tVSyIet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip MMM.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F0jdp6jJxb3",
        "colab_type": "text"
      },
      "source": [
        "Remove the ZIP file(You may need to change the name (MMM.zip)) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmE68AT6yK3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm MMM.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b24Jp6GvJy86",
        "colab_type": "text"
      },
      "source": [
        "Move back to the stylegan folder :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04StmZ6IyyOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/stylegan/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_46XSqaJ2wA",
        "colab_type": "text"
      },
      "source": [
        "You could run this line to see all the images listed :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdEmyMNWIIwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/stylegan/originals/MMM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIbxsKS8J7LS",
        "colab_type": "text"
      },
      "source": [
        "Transform the JPGs to tfRecords (You may need to change the path):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PhTG_5KLlJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python dataset_tool.py create_from_images datasets/letterABC ./originals/MMM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfkQBinYKIay",
        "colab_type": "text"
      },
      "source": [
        "Adjusting the train.py file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwbz3Dchu4Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile train.py \n",
        "\n",
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Main entry point for training StyleGAN and ProGAN networks.\"\"\"\n",
        "\n",
        "import copy\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "\n",
        "import config\n",
        "from metrics import metric_base\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Official training configs for StyleGAN, targeted mainly for FFHQ.\n",
        "\n",
        "if 1:\n",
        "    desc          = 'sgan'                                                                 # Description string included in result subdir name.\n",
        "    train         = EasyDict(run_func_name='training.training_loop.training_loop')         # Options for training loop.\n",
        "    G             = EasyDict(func_name='training.networks_stylegan.G_style')               # Options for generator network.\n",
        "    D             = EasyDict(func_name='training.networks_stylegan.D_basic')               # Options for discriminator network.\n",
        "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for generator optimizer.\n",
        "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for discriminator optimizer.\n",
        "    G_loss        = EasyDict(func_name='training.loss.G_logistic_nonsaturating')           # Options for generator loss.\n",
        "    D_loss        = EasyDict(func_name='training.loss.D_logistic_simplegp', r1_gamma=10.0) # Options for discriminator loss.\n",
        "    dataset       = EasyDict()                                                             # Options for load_dataset().\n",
        "    sched         = EasyDict()                                                             # Options for TrainingSchedule.\n",
        "    grid          = EasyDict(size='4k', layout='random')                                   # Options for setup_snapshot_image_grid().\n",
        "    metrics       = [metric_base.fid50k]                                                   # Options for MetricGroup.\n",
        "    submit_config = dnnlib.SubmitConfig()                                                  # Options for dnnlib.submit_run().\n",
        "    tf_config     = {'rnd.np_random_seed': 1000}                                           # Options for tflib.init_tf().\n",
        "\n",
        "    # Dataset.\n",
        "    desc += '-letterABC';     dataset = EasyDict(tfrecord_dir='letterABC', resolution=64); train.mirror_augment = False\n",
        "    #desc += '-ffhq512';  dataset = EasyDict(tfrecord_dir='ffhq', resolution=512); train.mirror_augment = True\n",
        "    #desc += '-ffhq256';  dataset = EasyDict(tfrecord_dir='ffhq', resolution=256); train.mirror_augment = True\n",
        "    #desc += '-celebahq'; dataset = EasyDict(tfrecord_dir='celebahq');             train.mirror_augment = True\n",
        "    #desc += '-bedroom';  dataset = EasyDict(tfrecord_dir='lsun-bedroom-full');    train.mirror_augment = False\n",
        "    #desc += '-car';      dataset = EasyDict(tfrecord_dir='lsun-car-512x384');     train.mirror_augment = False\n",
        "    #desc += '-cat';      dataset = EasyDict(tfrecord_dir='lsun-cat-full');        train.mirror_augment = False\n",
        "\n",
        "    # Number of GPUs.\n",
        "    desc += '-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}\n",
        "    #desc += '-2gpu'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}\n",
        "    #desc += '-4gpu'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
        "    #desc += '-8gpu'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
        "\n",
        "    # Default options.\n",
        "    train.total_kimg = 25000\n",
        "    sched.lod_initial_resolution = 8\n",
        "    sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
        "    sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
        "\n",
        "    # WGAN-GP loss for CelebA-HQ.\n",
        "    #desc += '-wgangp'; G_loss = EasyDict(func_name='training.loss.G_wgan'); D_loss = EasyDict(func_name='training.loss.D_wgan_gp'); sched.G_lrate_dict = {k: min(v, 0.002) for k, v in sched.G_lrate_dict.items()}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
        "\n",
        "    # Table 1.\n",
        "    #desc += '-tuned-baseline'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-add-mapping-and-styles'; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-remove-traditional-input'; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-add-noise-inputs'; G.style_mixing_prob = 0.0\n",
        "    #desc += '-mixing-regularization' # default\n",
        "\n",
        "    # Table 2.\n",
        "    #desc += '-mix0'; G.style_mixing_prob = 0.0\n",
        "    #desc += '-mix50'; G.style_mixing_prob = 0.5\n",
        "    #desc += '-mix90'; G.style_mixing_prob = 0.9 # default\n",
        "    #desc += '-mix100'; G.style_mixing_prob = 1.0\n",
        "\n",
        "    # Table 4.\n",
        "    #desc += '-traditional-0'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-traditional-8'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 8; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-stylebased-0'; G.mapping_layers = 0\n",
        "    #desc += '-stylebased-1'; G.mapping_layers = 1\n",
        "    #desc += '-stylebased-2'; G.mapping_layers = 2\n",
        "    #desc += '-stylebased-8'; G.mapping_layers = 8 # default\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Official training configs for Progressive GAN, targeted mainly for CelebA-HQ.\n",
        "\n",
        "if 0:\n",
        "    desc          = 'pgan'                                                         # Description string included in result subdir name.\n",
        "    train         = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "    G             = EasyDict(func_name='training.networks_progan.G_paper')         # Options for generator network.\n",
        "    D             = EasyDict(func_name='training.networks_progan.D_paper')         # Options for discriminator network.\n",
        "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "    G_loss        = EasyDict(func_name='training.loss.G_wgan')                     # Options for generator loss.\n",
        "    D_loss        = EasyDict(func_name='training.loss.D_wgan_gp')                  # Options for discriminator loss.\n",
        "    dataset       = EasyDict()                                                     # Options for load_dataset().\n",
        "    sched         = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "    grid          = EasyDict(size='1080p', layout='random')                        # Options for setup_snapshot_image_grid().\n",
        "    metrics       = [metric_base.fid50k]                                           # Options for MetricGroup.\n",
        "    submit_config = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "    tf_config     = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "    # Dataset (choose one).\n",
        "    desc += '-celebahq';            dataset = EasyDict(tfrecord_dir='celebahq'); train.mirror_augment = True\n",
        "    #desc += '-celeba';              dataset = EasyDict(tfrecord_dir='celeba'); train.mirror_augment = True\n",
        "    #desc += '-cifar10';             dataset = EasyDict(tfrecord_dir='cifar10')\n",
        "    #desc += '-cifar100';            dataset = EasyDict(tfrecord_dir='cifar100')\n",
        "    #desc += '-svhn';                dataset = EasyDict(tfrecord_dir='svhn')\n",
        "    #desc += '-mnist';               dataset = EasyDict(tfrecord_dir='mnist')\n",
        "    #desc += '-mnistrgb';            dataset = EasyDict(tfrecord_dir='mnistrgb')\n",
        "    #desc += '-syn1024rgb';          dataset = EasyDict(class_name='training.dataset.SyntheticDataset', resolution=1024, num_channels=3)\n",
        "    #desc += '-lsun-airplane';       dataset = EasyDict(tfrecord_dir='lsun-airplane-100k');       train.mirror_augment = True\n",
        "    #desc += '-lsun-bedroom';        dataset = EasyDict(tfrecord_dir='lsun-bedroom-100k');        train.mirror_augment = True\n",
        "    #desc += '-lsun-bicycle';        dataset = EasyDict(tfrecord_dir='lsun-bicycle-100k');        train.mirror_augment = True\n",
        "    #desc += '-lsun-bird';           dataset = EasyDict(tfrecord_dir='lsun-bird-100k');           train.mirror_augment = True\n",
        "    #desc += '-lsun-boat';           dataset = EasyDict(tfrecord_dir='lsun-boat-100k');           train.mirror_augment = True\n",
        "    #desc += '-lsun-bottle';         dataset = EasyDict(tfrecord_dir='lsun-bottle-100k');         train.mirror_augment = True\n",
        "    #desc += '-lsun-bridge';         dataset = EasyDict(tfrecord_dir='lsun-bridge-100k');         train.mirror_augment = True\n",
        "    #desc += '-lsun-bus';            dataset = EasyDict(tfrecord_dir='lsun-bus-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-car';            dataset = EasyDict(tfrecord_dir='lsun-car-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-cat';            dataset = EasyDict(tfrecord_dir='lsun-cat-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-chair';          dataset = EasyDict(tfrecord_dir='lsun-chair-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-churchoutdoor';  dataset = EasyDict(tfrecord_dir='lsun-churchoutdoor-100k');  train.mirror_augment = True\n",
        "    #desc += '-lsun-classroom';      dataset = EasyDict(tfrecord_dir='lsun-classroom-100k');      train.mirror_augment = True\n",
        "    #desc += '-lsun-conferenceroom'; dataset = EasyDict(tfrecord_dir='lsun-conferenceroom-100k'); train.mirror_augment = True\n",
        "    #desc += '-lsun-cow';            dataset = EasyDict(tfrecord_dir='lsun-cow-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-diningroom';     dataset = EasyDict(tfrecord_dir='lsun-diningroom-100k');     train.mirror_augment = True\n",
        "    #desc += '-lsun-diningtable';    dataset = EasyDict(tfrecord_dir='lsun-diningtable-100k');    train.mirror_augment = True\n",
        "    #desc += '-lsun-dog';            dataset = EasyDict(tfrecord_dir='lsun-dog-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-horse';          dataset = EasyDict(tfrecord_dir='lsun-horse-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-kitchen';        dataset = EasyDict(tfrecord_dir='lsun-kitchen-100k');        train.mirror_augment = True\n",
        "    #desc += '-lsun-livingroom';     dataset = EasyDict(tfrecord_dir='lsun-livingroom-100k');     train.mirror_augment = True\n",
        "    #desc += '-lsun-motorbike';      dataset = EasyDict(tfrecord_dir='lsun-motorbike-100k');      train.mirror_augment = True\n",
        "    #desc += '-lsun-person';         dataset = EasyDict(tfrecord_dir='lsun-person-100k');         train.mirror_augment = True\n",
        "    #desc += '-lsun-pottedplant';    dataset = EasyDict(tfrecord_dir='lsun-pottedplant-100k');    train.mirror_augment = True\n",
        "    #desc += '-lsun-restaurant';     dataset = EasyDict(tfrecord_dir='lsun-restaurant-100k');     train.mirror_augment = True\n",
        "    #desc += '-lsun-sheep';          dataset = EasyDict(tfrecord_dir='lsun-sheep-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-sofa';           dataset = EasyDict(tfrecord_dir='lsun-sofa-100k');           train.mirror_augment = True\n",
        "    #desc += '-lsun-tower';          dataset = EasyDict(tfrecord_dir='lsun-tower-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-train';          dataset = EasyDict(tfrecord_dir='lsun-train-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-tvmonitor';      dataset = EasyDict(tfrecord_dir='lsun-tvmonitor-100k');      train.mirror_augment = True\n",
        "\n",
        "    # Conditioning & snapshot options.\n",
        "    #desc += '-cond'; dataset.max_label_size = 'full' # conditioned on full label\n",
        "    #desc += '-cond1'; dataset.max_label_size = 1 # conditioned on first component of the label\n",
        "    #desc += '-g4k'; grid.size = '4k'\n",
        "    #desc += '-grpc'; grid.layout = 'row_per_class'\n",
        "\n",
        "    # Config presets (choose one).\n",
        "    #desc += '-preset-v1-1gpu'; submit_config.num_gpus = 1; D.mbstd_group_size = 16; sched.minibatch_base = 16; sched.minibatch_dict = {256: 14, 512: 6, 1024: 3}; sched.lod_training_kimg = 800; sched.lod_transition_kimg = 800; train.total_kimg = 19000\n",
        "    desc += '-preset-v2-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}; sched.G_lrate_dict = {1024: 0.0015}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-2gpus'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}; sched.G_lrate_dict = {512: 0.0015, 1024: 0.002}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-4gpus'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}; sched.G_lrate_dict = {256: 0.0015, 512: 0.002, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-8gpus'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}; sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "\n",
        "    # Numerical precision (choose one).\n",
        "    desc += '-fp32'; sched.max_minibatch_per_gpu = {256: 16, 512: 8, 1024: 4}\n",
        "    #desc += '-fp16'; G.dtype = 'float16'; D.dtype = 'float16'; G.pixelnorm_epsilon=1e-4; G_opt.use_loss_scaling = True; D_opt.use_loss_scaling = True; sched.max_minibatch_per_gpu = {512: 16, 1024: 8}\n",
        "\n",
        "    # Disable individual features.\n",
        "    #desc += '-nogrowing'; sched.lod_initial_resolution = 1024; sched.lod_training_kimg = 0; sched.lod_transition_kimg = 0; train.total_kimg = 10000\n",
        "    #desc += '-nopixelnorm'; G.use_pixelnorm = False\n",
        "    #desc += '-nowscale'; G.use_wscale = False; D.use_wscale = False\n",
        "    #desc += '-noleakyrelu'; G.use_leakyrelu = False\n",
        "    #desc += '-nosmoothing'; train.G_smoothing_kimg = 0.0\n",
        "    #desc += '-norepeat'; train.minibatch_repeats = 1\n",
        "    #desc += '-noreset'; train.reset_opt_for_new_lod = False\n",
        "\n",
        "    # Special modes.\n",
        "    #desc += '-BENCHMARK'; sched.lod_initial_resolution = 4; sched.lod_training_kimg = 3; sched.lod_transition_kimg = 3; train.total_kimg = (8*2+1)*3; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
        "    #desc += '-BENCHMARK0'; sched.lod_initial_resolution = 1024; train.total_kimg = 10; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
        "    #desc += '-VERBOSE'; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1; train.network_snapshot_ticks = 100\n",
        "    #desc += '-GRAPH'; train.save_tf_graph = True\n",
        "    #desc += '-HIST'; train.save_weight_histograms = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main entry point for training.\n",
        "# Calls the function indicated by 'train' using the selected options.\n",
        "\n",
        "def main():\n",
        "    kwargs = EasyDict(train)\n",
        "    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "    kwargs.update(dataset_args=dataset, sched_args=sched, grid_args=grid, metric_arg_list=metrics, tf_config=tf_config)\n",
        "    kwargs.submit_config = copy.deepcopy(submit_config)\n",
        "    kwargs.submit_config.run_dir_root = dnnlib.submission.submit.get_template_from_path(config.result_dir)\n",
        "    kwargs.submit_config.run_dir_ignore += config.run_dir_ignore\n",
        "    kwargs.submit_config.run_desc = desc\n",
        "    dnnlib.submit_run(**kwargs)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax-9fMJ8KQKD",
        "colab_type": "text"
      },
      "source": [
        "Run the train.py file and wait :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COsTRhxzu46X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBAeTgGKTpc",
        "colab_type": "text"
      },
      "source": [
        "You will start finding results in the results folder ;) Download the network-snapshot to use them later to generate new images. Watch out that Google Colab kicks you out after circa 6 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFMsTFavKnl8",
        "colab_type": "text"
      },
      "source": [
        "Everything from here on shouldn't be touched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TObxx8vSie4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/stylegan/results/00000-sgan-letterM-1gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydIEIVa7ivzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg8_D-R9gcTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/backuptrain.zip /content/stylegan/results/00000-sgan-letterABC-1gpu"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}